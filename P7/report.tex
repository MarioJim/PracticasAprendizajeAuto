\documentclass[sigconf,authorversion,nonacm]{acmart}

\usepackage{FiraMono}
\usepackage{listings}
\captionsetup{justification=centering, margin=1cm}


\begin{document}

\title{Práctica 7 \\ Máquinas de soporte vectorial}

\author{Mario Emilio Jiménez Vizcaíno}
\email{A01173359@itesm.mx}
\affiliation{%
  \institution{Tecnológico de Monterrey \\ Ingeniería en Tecnologías Computacionales}
  \city{Monterrey, N.L.}
  \country{México}
}

\author{Jesus Abraham Haros Madrid}
\email{A01252642@itesm.mx}
\affiliation{%
  \institution{Tecnológico de Monterrey \\ Ingeniería en Tecnologías Computacionales}
  \city{Monterrey, N.L.}
  \country{México}
}


\begin{abstract}
  \textbf{TODO}
\end{abstract}

\maketitle

\section{Introducción}
\textbf{TODO}


\section{Conceptos previos}
\begin{itemize}
  \item Programación básica en Python
  \item Conocimiento de las librerías \textit{scikit-learn}, \textit{matplotlib} y \textit{numpy}
  \item Conocimientos básicos de estadística
\end{itemize}


\section{Metodología}
Ésta práctica, al igual que la práctica pasada, implementar los modelos fue una tarea fácil, ya que la metodología para llevarla a cabo fue muy clara en la descripción de la actividad. Es por eso que nos guiamos de los pasos descritos en el documento de la práctica 7 para poder implementar los scripts de Python.

Para demostrar la eficacia y los resultados de las máquinas de soporte vectorial las comparamos contra tres modelos más:
\begin{itemize}
  \item Un modelo de regresión logística
  \item Un modelo de k-vecinos más cercanos: durante nuestras pruebas encontramos el valor óptimo para k como 1, con una máxima precisión de 0.9889. El código de nuestra prueba puede ser encontrado en el apéndice \ref{appendix:knnpy}
  \item Un modelo de Bayes ingenuo
\end{itemize}

Para poder hacer el script fácil de usar con los diferentes modelos de clasificación se optó por leer como argumento de ejecución de programa el modelo con el que se quiere trabajar.


\subsection{Dataset Digits}
\textbf{TODO}


\subsection{Máquinas de soporte vectorial}
\textbf{TODO}

El código que ejecutamos para realizar el análisis del dataset se encuentra en el apéndice \ref{appendix:py}.


\section{Resultados}
Una vez entrenados y probados los diferentes modelos utilizados en esta práctica fue muy interesante observar como la mayoría tienen un excelente desempeño para clasificar instancias.

Comenzaremos por mostrar los resultados obtenidos utilizando las maquinas de soporte vectorial, se utilizaron cuatro kernels distintos y se logran apreciar las diferencias entre cada uno. Después se mostrarán los resultados obtenidos con métodos de clasificación utilizados en prácticas anteriores y por último se comprarán todos estos modelos para mostrar sus diferencias.

\subsection{Precisión de los modelos}
\begin{table}[H]
\begin{tabular}{|l|c|}
\hline
\multicolumn{1}{|c|}{\textbf{Modelo}} & \textbf{Precisión} \\ \hline
MSV con kernel lineal     & 0.9777    \\ \hline
MSV con kernel polinomial & 0.9889    \\ \hline
MSV con kernel RBF        & 0.9917    \\ \hline
MSV con kernel sigmoide   & 0.9139    \\ \hline
Regresión logística       & 0.9472    \\ \hline
k-Vecinos más cercanos    & 0.9889     \\ \hline
Bayes ingenuo             & 0.8444    \\ \hline
\end{tabular}
\end{table}

\subsection{Matriz de confusión de los modelos}
\subsubsection{SVM con kernel lineal}
Al utilizar el kernel lineal se puede ver como la mayoría de las instancias se clasifican correctamente, algunas quedan fuera, como el número 1 con dos clasificaciones falsas, pero en general el desempeño de la SVM con kernel lineal nos permite clasificar las instancias satisfactoriamente, en este caso se clasificó para múltiples clases (10) y aún así logra hacerlo bien.
La precisión obtenida del modelo fue de 0.9777

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{linear_cm.png}
  \caption{Matriz de confusión del modelo de máquina de soporte vectorial usando un kernel lineal}
\end{figure}

\subsubsection{SVM con kernel polinomial}
Al utilizar la maquina de soporte vectorial con kernel polinomial se observa una mejoría en el desempeño del modelo para clasificar, aunque el lineal ya era bueno este tiene aún mejores resultados. La matriz de confusión obtenida fue muy similar a la anterior, se observa que casi todos quedan clasificados correctamente y que las instancias clasificadas erróneamente son muy pocas (casi nulas).
La precisión obtenida del modelo fue de 0.9888

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{poly_cm.png}
  \caption{Matriz de confusión del modelo de máquina de soporte vectorial usando un kernel polinomial}
\end{figure}

\subsubsection{SVM con kernel RBF}
Cuando se utilizó como kernel la función de base radial (RBF) se notó una mejoría en la precisión del modelo para clasificar, aunque dichas mejorías no sean tan significativas (diferencias de 1%-2%) nos permite observar como utilizando las mismas maquinas de soporte vectorial con diferente kernel nos permite hacer un modelo mejor entrenado.
La precisión obtenida del modelo fue de 0.9916

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{rbf_cm.png}
  \caption{Matriz de confusión del modelo de máquina de soporte vectorial usando un kernel RBF}
\end{figure}

\subsubsection{SVM con kernel Sigmoide}
Para este punto los resultados de las maquinas de soporte vectorial erán muy prometedores, se pensaba que cada que se cambiaba el kernel habría mejoría, pero no fue el caso cuando se utilizó como kernel la sigmoide, la matriz de confusión nos muestra más errores al momento de clasificar las instancias aunque si clasifica la mayoría bien. Lo anterior también se ve reflejado en la precisión del modelo la cual fue más baja que los tres anteriores, seguramente el dataset y número de clases utilizadas no favoreció el desempeño de la SVM con este kernel.
La precisión obtenida del modelo fue de 0.9138

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{sigmoid_cm.png}
  \caption{Matriz de confusión del modelo de máquina de soporte vectorial usando un kernel sigmoide}
\end{figure}

\subsubsection{Regresión logística}
Después de utilizar SMVs probando cuatro kernels distintos llega el momento de probar los métodos de clasificación ya utilizados anteriormente, cabe aclarar que no se habían utilizado para predecir tantas clases, así que se comenzó por probar el modelo de regresión logística, los resultados obtenidos fueron muy buenos pero no tan buenos como algunas SVMs, la matriz de confusión muestra algunos errores y esto a su vez se refleja en la precisión obtenida por el modelo, aunque sigue sienda una muy buena precisión y que se probó que la regresión logística funciona para clasificar múltiples clases no quita el hecho de que las SVMs tienen un mejor desempeño (para este caso utilizando este dataset).
La precisión obtenida del modelo fue de 0.9472

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{logistic_cm.png}
  \caption{Matriz de confusión del modelo de regresión logística}
\end{figure}

\subsubsection{Knn}
Al utilizar como modelo de clasificación Knn el resultado fue que es uno de los mejores para clasificación múltiple, su desempeño fue muy similar a la mejor SVM (polinomial) y la matriz de confusión lo muestra, se ven muy pocos errores y que casi todos se encuentran clasificados correctamente.
La precisión obtenida del modelo fue de 0.9888

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{knn_cm.png}
  \caption{Matriz de confusión del modelo de k vecinos más cercanos}
\end{figure}

\subsubsection{Bayesiano ingenuo}
Por último se compara el modelo bayesiano ingenuo el cual no mostró una mejoría respecto a los modelos mencionados anteriormente, de hecho ha sido el modelo con peor desempeño, puede ser por que fueron muchas clases a clasificar.
La precisión obtenida del modelo fue de 0.8444

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{bayes_cm.png}
  \caption{Matriz de confusión del modelo bayesiano ingenuo}
\end{figure}

\subsection{Espacio ROC de los modelos}
Para todos los clasificadores implementados en esta practica se observaron matrices de confusión muy similares, todos clasificaron la mayoría de las instancias correctamente lo cual es bueno, pero debido a que eran muchas clases la matriz de confusión se vuelve difícil de leer para poder comparar los clasificadores, en este caso una buena métrica podría ser compararlos en base a su precisión, pero si queremos tomar una vista más general del modelo y tomar en cuenta más que su precisión deberemos de utilizar el espacio ROC para compararlos.

El espacio ROC nos sirve para poder identificar las ventajas y desventajas de cada clasificador graficando el promedio de los falsos positivos y verdaderos positivos en un plano. Lo ideal para un modelo es que este su TPR esté lo más cercano al 1 y su FPR lo más cercano al 0, esa sería la precisión ideal de predicción. Se hará una pequeña modificación para poder emplearlos con múltiples clases y se tomará el macro para graficar el espacio ROC.

El resultado final fue que la mayoría de las SVMs tienen un excelente desempeño y son ideales para este dataset, a excepción de la SVM con kernel sigmoide la cual fue la más baja de todas, el segundo peor modelo fue bayes y despues todas las SVMs junto con Knn y regresión logística presentan los mejores resultados (entre 0.99 y 1), recordando que el mayor desempeño es de 1.
\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{ROC_curve.png}
  \caption{Gráfica de comparación de los modelos en el espacio ROC}
\end{figure}

\section{Conclusiones y reflexiones}
Esta practica fue todo un reto ya que no se habían utilizado clasificadores para múltiples clases, por lo cual no se sabía como iban a ser los resultados arrojados por los modelos, al implementarlos y observar las matrices de confusión obtenidas se aprecia que la mayoría de los clasificadores son muy buenos y tienen pocos errores (unos mas que otros), también se observa que los métodos de clasificación utilizados en practicas anteriores funcionaron óptimamente para múltiples clases.

Las maquinas de soporte vectorial muestran desempeño excelente para clasificar, pero al iterar sobre los diferentes kernels nos dimos cuenta que unos tienen mejor desempeño que otros, aunque depende del dataset y del caso de uso, se debe de tener en cuenta que la selección del kernel impactará el desempeño del modelo por lo que se recomienda hacer algo muy parecido con Knn para encontrar la K ideal, iterar sobre los kernels para ver cual tiene mejor precisión.

En general todos los modelos tuvieron muy buen desempeño, fue muy interesante ver como la precisión cambia entre cada uno pero oscilan en rangos muy similares.

Por último al observar el espacio ROC nos damos cuenta que el modelo ideal está entre algunas SVMs y regresión logística, pero fue interesante ver como Naive bayes tiene la peor precisión mientras que el modelo con el peor desempeño en el espacio ROC es la SVM con sigmoide, esto nos muestra que no solo debemos de seleccionar un modelo por su precisión si no que es valioso ver como se comporta en el espacio ROC para tomar decisiones.

\subsection{Refrexión de Abraham}
Esta fue una de las prácticas más interesantes hasta el momento ya que la complejidad del codigo no fue muy alta lo que nos permitió enfocarnos en el analisis de resultados y comparación del desempeño de los clasificadores, me gustó ver como se comportan al clasificar múltiples clases lo cual me será útil para mi proyecto, y también me pareció muy valioso saber que se tienen que probar diferentes kernels para ver cual es el más óptimo para una SVM.

También ver que el espacio ROC nos muestra una mejor vista de los modelos me será de gran utilidad para no guiarme solo por su precisión.

Este trabajo me ayudó a comprender los conceptos de aprendizaje automático vistos en clase y a desarrollar mi capacidad de analizar y comparar.


\subsection{Reflexión de Mario}
\textbf{TODO}


\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\clearpage

\appendix

\lstdefinestyle{customstyle}{
  basicstyle=\ttfamily,
  frame=single,
  numbers=left,
  numbersep=5pt,
  showstringspaces=false
}
\lstset{style=customstyle}

\begin{figure*}
  \section{Código para la comparación de modelos de clasificación}
  \label{appendix:py}
  \lstinputlisting[language=Python,lastline=52]{practice7.py}
\end{figure*}

\begin{figure*}
  \lstinputlisting[language=Python,firstnumber=54,firstline=54]{practice7.py}
\end{figure*}

\begin{figure*}
  \section{Código para la comparación de k para el modelo de k-vecinos más cercanos}
  \label{appendix:knnpy}
  \lstinputlisting[language=Python]{knn-search.py}
\end{figure*}

\begin{figure*}
  \section{Código para la comparación y graficación del espacio ROC}
  \label{appendix:knnpy}
  \lstinputlisting[language=Python]{ROC_space.py}
\end{figure*}

\end{document}
\endinput
