\documentclass[sigconf,authorversion,nonacm]{acmart}

\usepackage{FiraMono}
\usepackage{listings}
\captionsetup{justification=centering, margin=1cm}


\begin{document}

\title{Práctica 5 \\ Árboles de decisión}

\author{Mario Emilio Jiménez Vizcaíno}
\email{A01173359@itesm.mx}
\affiliation{%
  \institution{Tecnológico de Monterrey \\ Ingeniería en Tecnologías Computacionales}
  \city{Monterrey, N.L.}
  \country{México}
}

\author{Jesus Abraham Haros Madrid}
\email{A01252642@itesm.mx}
\affiliation{%
  \institution{Tecnológico de Monterrey \\ Ingeniería en Tecnologías Computacionales}
  \city{Monterrey, N.L.}
  \country{México}
}


\begin{abstract}
  En la actualidad, uno de los problemas más importantes para los científicos es la clasificación: el etiquetado de elementos, basándose en las características de estos, seleccionando de un conjunto de clases, una que mejor lo represente. Los árboles de decisión, el objeto de estudio en esta práctica, son clasificadores que predicen las clases de los elementos usando algoritmos simples, lo que facilita su uso e implementación.
\end{abstract}

\maketitle

\section{Introducción}
Un árbol de decisión clasifica instancias de datos planteando una serie de preguntas sobre las características de estos elementos. Cada pregunta se representa con un nodo, y cada nodo apunta a un nodo hijo, que puede ser un nodo terminal (que presenta el resultado del árbol: una clase o etiqueta), u otro nodo de decisión. Las preguntas forman así una jerarquía de decisiones capturada en una estructura de árbol.

Para clasificar un elemento se sigue el camino desde el nodo superior o raíz, hasta un nodo terminal, dependiendo las características del nodo y las preguntas que cada hoja del camino presenten.

Una ventaja de los árboles de decisión es que muchas veces son más interpretables que otros clasificadores, como las redes neuronales y las máquinas de vectores de soporte\cite{kingsford2008decision}, porque combinan preguntas sencillas sobre los datos de forma comprensible. Por desgracia, pequeños cambios en los datos de entrada pueden provocar a veces grandes cambios en el árbol construido. Los árboles de decisión son lo suficientemente flexibles como para manejar elementos con una mezcla de características de valor real y categóricas, así como elementos con algunas características ausentes.


\section{Conceptos previos}
\begin{itemize}
  \item Programación básica en Python
  \item Conocimiento de las librerías \textit{scikit-learn}, \textit{matplotlib} y \textit{numpy}
  \item Conocimientos básicos de estadística
\end{itemize}


\section{Metodología}
Esta fue la primera práctica donde la metodología para llevarla a cabo fue muy clara en la descripción de la actividad, por lo que se siguieron los pasos descritos en el documento de la práctica 5.

Se comenzó por instalar \textit{graphviz} en las computadoras, seguido de corroborar que se tenía instalado \textit{numpy}, \textit{matplotlib} y \textit{scikit-learn}.
Una vez hecho esto se creó el archivo llamado \texttt{practice5.py} y se configuró para que al entrenar el modelo las visualizaciones fueran estéticamente vistosas, así como también establecer el directorio donde se guardarían.

Se comenzó por entrenar un árbol de decisión para el dataset Iris incluido en la librería de \textit{scikit-learn}, una vez entrenado se dibujó utilizando \textit{graphviz}.
Después, se probó el árbol de decisión utilizando los conjuntos de entrenamiento y prueba, y se calculó la precisión del modelo.

Para poder hacer el script genérico se optó por utilizar el módulo \textit{sys} y leer como argumento el dataset con el que se quiere trabajar.

\subsection{Dataset Iris}
Se utilizó el dataset Iris incluido en la librería de \textit{scikit-learn}, para esta práctica se tomaron solo los dos últimos features (petal length y petal width) de los datos ya que el código proporcionado para graficar los resultados se establecían sólo esas dos columnas. 
Una vez seleccionadas las columnas se entrena el modelo y se grafica el árbol de decisión correspondiente.
Por último se calcula su precisión y se grafica la predicción del modelo para poder visualizar las particiones generadas por cada split.


\subsection{Dataset Wine}
Muy similar a lo que se hizo con el dataset Iris, se importó este dataset de la librería \textit{scikit-learn} pero en este caso tomamos todos los features.
Se entrenó el modelo y se graficó el árbol de decisión para este dataset.
Por último se calculó su precisión.


\subsection{Dataset Breast Cancer}
Al igual que lo que se hizo con el dataset Iris, se importó este dataset de la librería \textit{scikit-learn} y se utilizaron todos los features.
Se entrenó el modelo y se graficó el árbol de decisión para este dataset.
Por último se calculó su precisión.


\subsection{Modelo de árbol de decisión}
Para la generación del modelo del árbol de decisión se utilizó la implementación de la librería \textit{sklearn}, específicamente la clase \\\textit{sklearn.tree.DecisionTreeClassifier}\cite{scikit-learn}, que, aunque permite al usuario elegir qué algoritmo utilizar para medir la calidad de las preguntas dentro del árbol, utiliza por defecto el algoritmo de impureza de Gini. También decidimos limitar el número de hojas en los árboles a 6 para evitar caer en \textit{overfitting} sobre los datos de entrenamiento.

El código que ejecutamos para realizar el análisis del dataset se encuentra en el apéndice \ref{appendix:py}.


\section{Resultados}
Los resultados obtenidos en está práctica fueron muy similares para los tres datasets, y gracias a las librerías mencionadas anteriormente se pudo generar una imagen con el árbol de decisión entrenado a partir de los conjuntos de entrenamiento y prueba de cada dataset.
A continuación se presentan los resultados para cada uno:


\subsection{Dataset Iris}
Se aprecia como el dato con mayor ganancia es "petal width" y en base a eso se empieza a determinar la clasificación.

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{images/decision_trees/iris_tree.png}
  \caption{Modelo de árbol de decisión generado para el dataset Iris}
\end{figure}

Al graficar los resultados del modelo y ver donde se clasifican las instancias se puede ver que es muy preciso y que muy pocas instancias quedan fuera de la clase a la que pertenecen.

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{images/decision_trees/decision_tree_decision_boundaries_plot.png}
  \caption{Resultados del modelo del árbol de decisión generado para el dataset Iris}
\end{figure}

Este árbol de decisión tuvo una precisión de 0.974 al ser comparado con el conjunto de datos de prueba.

\subsection{Dataset Wine}
Como en este dataset no se quitaron features, el árbol de decisión generado se nota más detallado, siendo color\_intensity el atributo con mayor ganancia.

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{images/decision_trees/wine_tree.png}
  \caption{Modelo de árbol de decisión generado para el dataset wine}
\end{figure}

Este árbol de decisión tuvo una precisión de 0.933 al ser comparado con el conjunto de datos de prueba.

\subsection{Dataset Breast Cancer}
Este fue el dataset con mayor número de atributos, inicialmente el resultado fue un árbol muy grande, pero después de recortarlo al máximo de 6 nodos hoja obtuvimos el siguiente árbol, siendo "mean concave points" el atributo con mayor ganancia.

\begin{figure}[H]
  \centering
  \includegraphics[width=200pt]{images/decision_trees/breast_cancer_tree.png}
  \caption{Modelo de árbol de decisión generado para el dataset breast\_cancer}
\end{figure}

Este árbol de decisión tuvo una precisión de 0.958 al ser comparado con el conjunto de datos de prueba.

\section{Conclusiones y reflexiones}
Los árboles de decisión son herramientas muy útiles para poder clasificar instancias y a la vez poder visualizar qué está pasando dentro del modelo. Claro que entre más features se tengan más difícil será visualizar el árbol y más extenso el trabajo de graficar resultados de prueba. La serie de preguntas de un árbol de decisión está ordenada con los atributos que tienen mayor ganancia donde cada nodo apunta a un nodo hijo con una nueva pregunta o un nodo terminal.
Al utilizar el dataset Iris fue muy interesante ver cómo el modelo entrenado sí clasificaba correctamente la mayoría de los datos y poder observar el proceso que sigue para clasificarlos.

\subsection{Refrexión de Abraham}
Esta práctica fue sencilla de elaborar y refuerza lo que ya se había trabajado a mano dentro del examen parcial, me gustó poder visualizar el árbol de decisión del modelo entrenado y también poder comprobar si se clasificaban correctamente las instancias utilizando la segunda función para graficar.
Me parece una técnica muy útil cuando se trata de clasificar datos ya que se puede mostrar el proceso a los clientes que lo necesiten.
Por último, me hubiera gustado hacer las gráficas de comprobación para cada dataset pero se ve largo y hardcodeado de elaborar por lo que investigaré si existe alguna librería para hacerlo.


\subsection{Reflexión de Mario}
Por mi parte, considero que esta práctica me ayudó a comprender por qué se utilizan los árboles de decisión a pesar de que toman decisiones "codiciosas" y con son muy inestables cuando se seleccionan los datos utilizados para entrenar el árbol. Las características que yo pienso hacen del árbol de decisión un clasificador fácil de aprender y enseñar son que se puede representar gráficamente como lo hicimos en la sección resultados, además de que el proceso de clasificación de una instancia o elemento es una serie de preguntas simples.


\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\clearpage

\appendix

\lstdefinestyle{customstyle}{
  basicstyle=\ttfamily,
  frame=single,
  numbers=left,
  numbersep=5pt,
  showstringspaces=false
}
\lstset{style=customstyle}

\begin{figure*}
  \section{Código para la generación del árbol de decisión}
  \label{appendix:py}
  \lstinputlisting[language=Python,lastline=46]{practice5.py}
\end{figure*}

\begin{figure*}
  \lstinputlisting[language=Python,firstnumber=48,firstline=48]{practice5.py}
\end{figure*}

\end{document}
\endinput
