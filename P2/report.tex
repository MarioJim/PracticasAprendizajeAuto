\documentclass[sigconf,authorversion,nonacm]{acmart}

\usepackage{listings}

\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

\begin{document}

\title{Práctica 2 \\ Regresión logística}

\author{Mario Emilio Jiménez Vizcaíno}
\email{A01173359@itesm.mx}
\affiliation{%
  \institution{Tecnológico de Monterrey \\ Ingeniería en Tecnologías Computacionales}
  \city{Monterrey, N.L.}
  \country{México}
}

\author{Jesus Abraham Haros Madrid}
\email{A01252642@itesm.mx}
\affiliation{%
  \institution{Tecnológico de Monterrey \\ Ingeniería en Tecnologías Computacionales}
  \city{Monterrey, N.L.}
  \country{México}
}


\begin{abstract}
\end{abstract}

\maketitle

\section{Introducción}
Actualmente, los modelos de regresión se han convertido en uno de los componentes más útiles del análisis de datos y el aprendizaje automático, en donde sea necesario describir la relación entre una variable resultante y una o más variables independientes. En algunos casos, la variable de resultado es discreta y adopta dos o más valores, es por eso que el modelo de regresión logística se ha convertido en muchos campos como el método estándar de análisis en esta situación.\cite{hosmer2013applied}

En esta práctica demostraremos dos implementaciones de este modelo, la implementación de la librería de Python \textit{sci-kit learn} y nuestra implementación usando el método de gradiente descendente.


\section{Conceptos previos}
\begin{itemize}
  \item Programación básica en los lenguajes R y Python
  \item Conocimiento de las librerías scikit-learn, pandas y numpy
  \item Conocimientos de estadística y de regresión logística
\end{itemize}


\section{Metodología}

\subsection{Datasets}
Para comparar ambas implementaciones utilizamos dos datasets, expuestos a continuación:

\subsubsection{Dataset DEFAULT}\hfill\\
Este dataset está compuesto por 10,000 filas, cada una representa un cliente de un banco que puede o no cumplir con los pagos de su tarjeta de crédito (columna "default"). De cada cliente tenemos la siguiente información:
\begin{itemize}
  \item Columna "default": Tiene los valores "Yes"/"No", representa si la persona realizó el pago mínimo a su tarjeta de crédito.
  \item Columna "student": Valores "Yes"/"No", representa si el cliente es un estudiante en ese momento.
  \item Columna "balance": Número decimal positivo que representa el balance de la tarjeta de crédito del cliente. Promedio de 835.4, números en el rango [0, 2654.3].
  \item Columna "income": Número decimal positivo que representa los ingresos que tiene el cliente. Promedio de 33517, números en el rango [772, 73554]
\end{itemize}

De este dataset, nuestro objetivo es predecir la columna "default" a partir de los otros tres parámetros, y como preparación cambiamos los valores de "student" ("Yes"/"No") a valores 1 y 0 respectivamente.


\subsubsection{Dataset GENERO}\hfill\\
Este dataset representa las mediciones de peso y altura de 10,000 personas, en conjunto con el género de la persona a la que se realizaron las medidas. Las columnas son:
\begin{itemize}
  \item "Gender": Valores "Male"/"Female", el género de la persona a la que le corresponde esta fila de mediciones.
  \item "Height": La altura de la persona en pulgadas, promedio de 66.37, en el rango [54.26 y 79.00].
  \item "Weight": El peso de la persona en libras, promedio de 161.4, en el rango [64.7, 270.0].
\end{itemize}

La columna objetivo seleccionada de este dataset fue el género ya que tiene dos clasificaciones.


\subsection{Regresión logística con \textit{sklearn}}
Para la primera parte de la práctica, en la que utilizamos la implementación de \textit{sci-kit learn}, seleccionamos la clase \newline\textit{sklearn.linear\_model.LogisticRegression}\cite{scikit-learn} para nuestros scripts.

\subsubsection{Dataset DEFAULT}\hfill\\
Para este dataset primero leemos el archivo CSV a un \textit{Dataframe} de \textit{pandas}, transformamos las columnas "default" y "student" para que contengan valores booleanos y enteros respectivamente, seleccionamos las columnas que nos servirán como variables independientes (columnas "student", "balance" e "income") y variable dependiente (columna "default"). Después partimos las filas del dataset en una porción del 80\% que usaremos para entrenar el modelo, y otra porción del 20\% para probarlo.

Instanciamos el modelo de regresión de \textit{sklearn}, lo entrenamos con los datos y después predecimos la variable dependiente con el modelo para así compararlo con los datos reales de prueba, usando una medida de tasa de precisión y la matriz de confusión.

El código de este ejemplo puede se encuentra en el apéndice A.

\subsubsection{Dataset GENERO}\hfill\\
Para este dataset realizamos un procedimiento similar: leer el dataset para crear un \textit{Dataframe}, seleccionar las columnas de variables independientes ("Height" y "Weight") y la dependiente ("Gender"), dividir el dataset en 80\%/20\%, entrenar el modelo, y predecir la variable dependiente para los datos de prueba, para así comparar estos con los datos reales.

El código para esta sección se encuentra en el apéndice B.


\subsection{Regresión logística con Gradiente Descendente}
En esta sección de la práctica implementamos nuestra propia clase de gradiente descendente, e intentamos que los métodos de nuestro modelo fueran muy parecidos a los de la clase de \textit{sklearn} para que así fuera fácil intercambiar las implementaciones. A pesar de esto, implementamos algunas diferencias para que el código funcionara correctamente.

Nuestra implementación del modelo de regresión logística se encuentra en el apéndice C.

Para implementar el gradiente descendente en esta practica se tuvo que hacer algunas modificaciones al algoritmo descrito en nuestra practica 1. Se tuvo que cambiar el algoritmo internamente al momento de hacer el calculo de theta, agregando el calculo de Miu como se describe en los requisitos de la practica, con esto podemos calcular correctamente la theta de nuestro modelo, y al momento de usar la predicción se agrego la función sigmoide para que nos posicionara todos los resultados predichos de 0 a 1 y así poder clasificar los datos en grupos, es por ello que se hizo una función para redondear el resultado de la función sigmoide. La predicción de nuestro gradiente descendente regresa una lista de 0 y 1, por ello se necesitan reconvertir estos valores a los originales del dataset, a continuación se explica lo que se hizo en cada uno para llegar al resultado deseado.

\subsubsection{Dataset DEFAULT}\hfill\\
Muy parecido a lo que ya se ha estado haciendo con scikit learn, para poder trabajar con este dataset tendremos que leerlo para crear un dataframe, transformando los valores de la columna “default” y student a valores Enteros para poder entrenar nuestro modelo, después de esto partimos el data set para 80% de entrenamiento y 20% de pruebas.

Instanciamos nuestro Gradiente Descendente, lo entrenamos con los datos y después predecimos la variable dependiente con el modelo, la diferencia y el paso extra que tuvimos que hacer fue reconvertir la variable default de numero entero a valor booleano para poder comparar con el dataset original (esto pudo haberse hecho tambien convirtiendo el dataset original a numero entero, pero se decidio hacerse de esta manera para preservar los valores del dataset).

El código fuente de este ejemplo se encuentra en el apéndice D.

\subsubsection{Dataset GENERO}\hfill\\
Al igual que con el dataset default, para poder predecir la variable dependiente en este dataset se utilizó lo mismo que en su implementación para scikit learn pero agregando una conversión de valores para la variable “genero”, convirtiéndola de los strings Male y Female a los valores enteros 0 y 1.

Una vez entrenado el modelo se revierte la conversión de valores para poder preservar los valores del dataset.

El código fuente puede ser encontrado en el apéndice E.

\section{Resultados}

\subsection{Regresión logística con \textit{sklearn}}

\subsubsection{Dataset DEFAULT}\hfill\\
El modelo de regresión logística de \textit{sklearn} tuvo una tasa de precisión alrededor de 0.965, con una gráfica de la matriz de confusión así:

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{default_cm_sklearn.png}
  \caption{Matriz de confusión del dataset DEFAULT con la implementación de sklearn}
\end{figure}

Se puede observar que la gran mayoría de los resultados son positivos, por lo que el modelo usualmente acierta al clasificar la casi la totalidad de las filas como positivas.

\subsubsection{Dataset GENERO}\hfill\\
En este ejemplo, el modelo de \textit{sklearn} tuvo una tasa de precisión cercana a 0.925, y una matriz de confusión de esta forma:

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{genero_cm_sklearn.png}
  \caption{Matriz de confusión del dataset GENERO con la implementación de sklearn}
\end{figure}

También se creó un diagrama de dispersión utilizando como eje X la altura de la persona, y en el eje Y el peso. Los puntos rojos representan personas del género femenino y los azules personas del género masculino.

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{genero_sklearn.png}
  \caption{Diagrama de dispersión del dataset GENERO con la implementación de sklearn}
\end{figure}

La gráfica superior representa el conjunto de valores de prueba, mientras que la gráfica inferior muestra el género predecido por el modelo de regresión a partir de los valores de prueba.

Para la generación de estas gráficas se utilizó el código incluído en el apéndice F.

\subsection{Regresión logística con Gradiente Descendente}

\subsubsection{Dataset DEFAULT}\hfill\\
El modelo de regresión logística con \textit{gradiente descendente} tuvo una tasa de precisión alrededor de 0.965, con una gráfica de la matriz de confusión así:

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{default_cm_sklearn.png}
  \caption{Matriz de confusión del dataset DEFAULT con la implementación del gradiente descendente}
\end{figure}

Muy parecido a los resultados del modelo de scikit learn obtuvimos la mayoría de los resultados como positivos, lo cual es un acierto debido a que en el dataset original la mayoría de los datos se encuentran como positivos.

\subsubsection{Dataset GENERO}\hfill\\
El modelo de regresión logística con \textit{gradiente descendente} tuvo una tasa de predicción de 0.8965, con una gráfica de la matriz de confusión así:

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{genero_cm_gradient.png}
  \caption{Matriz de confusión del dataset GENERO con la implementación del gradiente descendente}
\end{figure}

En este caso podemos ver como lo predicho por el modelo entrenado con scikit learn es un poco más preciso (aunque no muy notorio), aún asi su precisión es muy buena utilizando el gradiente descendente.

Para esto tambien se creó un diagrama de dispersión para poder comparar el dataset original contra el predicho por el modelo del gradiente descendente, en el eje X utilizamos la altura y en el eje Y el peso, los puntos rojos representan las personas de genero femenino y de azul las del genero masculino.

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{genero_gradient.png}
  \caption{Diagrama de dispersión del dataset GENERO con la implementación del gradiente descendente}
\end{figure}


\section{Conclusiones y reflexiones}
Existen múltiples formas de clasificar los datos de un dataset para poder hacer predicciones de variables y poder clasificarlas en grupos definidos, para esta práctica se utilizó la regresión logística que nos ayudó a clasificar los datos de ambos datasets, para el caso del genero nos ayudo a predecir el sexo dado altura y peso mientras que para el dataset default nos ayudó a predecir la columna default dadas las columnas student, balance e income. Al igual que en la practica anterior se predijeron los datos utilizando la librería scikit learn y el gradiente descendiente,

Se observaron resultados muy similares entre sklearn y el gradiente descendiente, en ambos hubo un problema al momento de predecir el dataset default y es que como hay muchos “yes” en la columna default, ambos modelos predecían como “Yes” para muchos casos, si se observan las gráficas de confusión de ambos modelos podemos apreciar como nunca predicen “No”.

\subsection{Refrexión de Abraham}
La practica pasada se me hizo muy complicado entender el funcionamiento interno del gradiente descendiente, sabía que hacía pero no como funcionaba, en esta practica, al tener que modificar el codigo interno de este, pude comprender mejor que está haciendo. Tambien se me hizo muy interesante la regresión logística y comprender la función sigmoide para poder clasificar y acotar los datos para dos categorías, me queda la duda sobre como clasificar para varias categorías pero supongo que ser verá en futuras practicas.

Esta práctica fue más sencilla de hacer por el hecho de que fue parecida a la anterior, fue más un refuerzo de la clase en vez de mucho investigación como la practica anterior. Cada vez aprendo más sobre las funciones de numpy y python para trabajar con datos y matrices, aunque aún me falta mucho por aprender, estoy satisfecho de poder hacer practicas como estas que confirman y refuerzan lo aprendido en clase.


\subsection{Reflexión de Mario}
Considero que esta práctica resolvió muchas de las dudas que tenía sobre la regresión logística y me ayudó a comprender en qué situaciones son útiles este tipo de algoritmos de clasificación, además de que, con el primer dataset, pude observar un ejemplo de un caso en el que probablemente la regresión logística no es la mejor solución a este problema ya que el dataset está demasiado sesgado hacia los clientes que no pagaron su tarjeta contra los que si.

Además, mejoré mis habilidades en Python utilizando librerías como sklearn, numpy y pandas, herramientas usadas frecuentemente en este tipo de análisis de datos por su facilidad de manipular grandes cantidades de información y abstraer modelos complejos, para ser expresados en pocas líneas de código.


\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\clearpage

\appendix

\lstdefinestyle{customstyle}{
  frame=single,
  numbers=left,
  numbersep=5pt,
  showstringspaces=false
}
\lstset{style=customstyle}

\begin{figure*}
  \section{Código de regresión logística con sklearn del dataset DEFAULT}
  \lstinputlisting[language=Python]{default_sklearn.py}
\end{figure*}

\begin{figure*}
  \section{Código de regresión logística con sklearn del dataset GENERO}
  \lstinputlisting[language=Python]{genero_sklearn.py}
\end{figure*}

\begin{figure*}
  \section{Nuestra implementación de gradiente descendente}
  \lstinputlisting[language=Python]{GradientDescent.py}
\end{figure*}

\begin{figure*}
  \section{Código de regresión logística con gradiente descendente del dataset DEFAULT}
  \lstinputlisting[language=Python]{default_gradiente.py}
\end{figure*}

\begin{figure*}
  \section{Código de regresión logística con gradiente descendente del dataset GENERO}
  \lstinputlisting[language=Python]{genero_gradiente.py}
\end{figure*}

\begin{figure*}
  \section{Código de generación de gráficas}
  \lstinputlisting[language=Python]{graphs.py}
\end{figure*}

\end{document}
\endinput
